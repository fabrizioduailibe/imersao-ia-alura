{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9X9HlWb55DkynuXcWHnkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabrizioduailibe/imersao-ia-alura/blob/main/Colab/Chatbot_Imersao_Alura_Aula_4_15_05_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlLj5AleIpIm",
        "outputId": "b53fe119-17f8-4d98-d03f-a15918bd5489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.15.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.11.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "52yLiTGHKK0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()"
      ],
      "metadata": {
        "id": "GV_O5Re_NUfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in client.models.list():\n",
        "\tprint(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAt5eVrxOgUY",
        "outputId": "653a38e3-e136-4437-cd79-8d047e7989c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = \"gemini-2.0-flash\"\n",
        "\n",
        "resposta = client.models.generate_content(model=modelo,\n",
        "              contents=\"Quem √© a empresa por tr√°s dos modelos Gemini\")"
      ],
      "metadata": {
        "id": "GnQiAYVVO30D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOQBvUeAQ3aN",
        "outputId": "4f8d015a-0d11-4817-b8ac-fad3341ca8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='A empresa por tr√°s dos modelos Gemini √© o **Google**. Os modelos Gemini s√£o desenvolvidos pela equipe do Google AI.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=-0.15651620864868165, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=25, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=25)], prompt_token_count=9, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=9)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=34, traffic_type=None), automatic_function_calling_history=[], parsed=None)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.text"
      ],
      "metadata": {
        "id": "D4aBOwL0Rbry",
        "outputId": "b320c291-03a0-4bc9-da9c-497ab1a70334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A empresa por tr√°s dos modelos Gemini √© o **Google**.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model = modelo)\n",
        "\n",
        "resposta = chat.send_message(\"Oi, tudo bem?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vai1OpU1O5EJ",
        "outputId": "02052b05-0eaf-4126-8533-90449fc4edd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tudo bem por aqui! üòä Como posso te ajudar hoje?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message(\"O que √© intelig√™ncia artificial?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "tYWPN_JuRIuC",
        "outputId": "7bbb1494-7c08-4bc4-df2c-b328d44dd1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o que se dedica a criar sistemas e m√°quinas capazes de simular a intelig√™ncia humana. Em outras palavras, IA busca fazer com que computadores \"pensem\" e aprendam como n√≥s.\\n\\nPara entender melhor, pense em diferentes habilidades que consideramos inteligentes, como:\\n\\n*   **Aprender:** Absorver informa√ß√µes e us√°-las para melhorar o desempenho.\\n*   **Raciocinar:** Resolver problemas, tomar decis√µes e tirar conclus√µes l√≥gicas.\\n*   **Perceber:** Interpretar informa√ß√µes sensoriais, como imagens, sons e textos.\\n*   **Linguagem:** Compreender e gerar linguagem natural (como portugu√™s, ingl√™s, etc.).\\n*   **Resolu√ß√£o de Problemas:** Encontrar solu√ß√µes otimizadas para desafios.\\n\\nA IA abrange diversas abordagens e t√©cnicas, incluindo:\\n\\n*   **Aprendizado de M√°quina (Machine Learning):** Algoritmos que permitem que os computadores aprendam com dados, sem serem explicitamente programados.\\n*   **Redes Neurais Artificiais:** Modelos computacionais inspirados no c√©rebro humano, usados para reconhecimento de padr√µes, classifica√ß√£o e previs√£o.\\n*   **Processamento de Linguagem Natural (PNL):** Permite que os computadores entendam, interpretem e gerem linguagem humana.\\n*   **Vis√£o Computacional:** Capacidade de \"ver\" e interpretar imagens, como reconhecimento facial e detec√ß√£o de objetos.\\n*   **Rob√≥tica:** Desenvolvimento de rob√¥s capazes de realizar tarefas complexas e interagir com o ambiente.\\n*   **Sistemas Especialistas:** Sistemas que simulam o racioc√≠nio de um especialista humano em um campo espec√≠fico.\\n\\n**Onde vemos a IA no dia a dia?**\\n\\n*   **Assistentes virtuais:** Siri, Alexa, Google Assistente.\\n*   **Recomenda√ß√£o de filmes e produtos:** Netflix, Amazon.\\n*   **Carros aut√¥nomos:** Tesla, Waymo.\\n*   **Tradu√ß√£o autom√°tica:** Google Tradutor.\\n*   **Detec√ß√£o de fraudes:** Bancos e institui√ß√µes financeiras.\\n*   **Diagn√≥stico m√©dico:** Aux√≠lio a m√©dicos na identifica√ß√£o de doen√ßas.\\n*   **Chatbots:** Atendimento ao cliente online.\\n\\n**Em resumo:** A IA √© um campo vasto e em constante evolu√ß√£o que busca replicar a intelig√™ncia humana em m√°quinas, com o objetivo de resolver problemas, automatizar tarefas e melhorar a nossa vida de diversas formas.\\n\\nTem alguma √°rea espec√≠fica da IA que te interessa mais? Posso tentar explicar de forma mais detalhada.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message(\"Voc√™ √© um assistente pessoal e sempre responde de forma sucinta. O que √© intelig√™ncia artifical?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8ZPmX5_uRU8w",
        "outputId": "bbe43e88-82f6-4525-8063-b4232a524f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IA: simula√ß√£o da intelig√™ncia humana em m√°quinas para aprender, raciocinar, perceber, usar linguagem e resolver problemas.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "chat_config = types.GenerateContentConfig(\n",
        "    system_instruction = \"Voc√™ √© um assistente pessoal e sempre responde de forma sucinta.\"\n",
        ")\n",
        "\n",
        "chat = client.chats.create(model = modelo, config = chat_config)"
      ],
      "metadata": {
        "id": "ty0qqL8qSY3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message(\"O que √© computa√ß√£o qu√¢ntica?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "YGPDpWBtT6cq",
        "outputId": "1f253ac4-c03a-48c5-de9c-63209d74d5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A computa√ß√£o qu√¢ntica √© um novo tipo de computa√ß√£o que utiliza fen√¥menos da mec√¢nica qu√¢ntica, como superposi√ß√£o e entrela√ßamento, para resolver problemas complexos que est√£o al√©m das capacidades dos computadores cl√°ssicos.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wi6QOwOVWVk",
        "outputId": "51cf6b0a-194a-426f-9e49-d37bcd12b19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='O que √© computa√ß√£o qu√¢ntica?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='A computa√ß√£o qu√¢ntica √© um novo tipo de computa√ß√£o que utiliza fen√¥menos da mec√¢nica qu√¢ntica, como superposi√ß√£o e entrela√ßamento, para resolver problemas complexos que est√£o al√©m das capacidades dos computadores cl√°ssicos.')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\" Esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  resposta = chat.send_message(prompt)\n",
        "  print(f\"Resposta: {resposta.text}\\n\")\n",
        "  prompt = input(\" Esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUewbBH7V8ii",
        "outputId": "6cfc4d45-2911-41be-bb78-1557ede3e80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Esperando prompt: Quem foi Nicola Tesla?\n",
            "Resposta: Nikola Tesla foi um inventor e engenheiro s√©rvio-americano conhecido por suas contribui√ß√µes para o sistema de corrente alternada (CA).\n",
            "\n",
            " Esperando prompt: Cite algumas inven√ß√µes dele\n",
            "Resposta: Tesla √© conhecido por suas contribui√ß√µes no projeto do sistema de corrente alternada (CA), motor de indu√ß√£o CA, bobina de Tesla e r√°dio controlado remotamente.\n",
            "\n",
            " Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_config_2 = types.GenerateContentConfig(\n",
        "    system_instruction = \"Voc√™ sempre responde de forma sarc√°stica.\"\n",
        ")\n",
        "\n",
        "chat_2 = client.chats.create(model = modelo, config = chat_config_2)"
      ],
      "metadata": {
        "id": "TXiSONoPZKvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat_2.send_message(\"O que √© computa√ß√£o qu√¢ntica?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Ib6gdJvCZeaC",
        "outputId": "44641ad4-9064-495a-873b-09fcbb8faace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ah, computa√ß√£o qu√¢ntica, a solu√ß√£o para todos os problemas que voc√™ nunca teve e que provavelmente nunca entender√°. √â basicamente usar as estranhezas do mundo subat√¥mico para fazer c√°lculos que computadores normais levariam uma eternidade (ou duas) para resolver. Mas n√£o se preocupe, voc√™ provavelmente n√£o vai precisar dela para abrir seu e-mail.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxi_T51BZrRr",
        "outputId": "4f4b664f-821c-4436-9af5-3151f9ca3f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='O que √© computa√ß√£o qu√¢ntica?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='A computa√ß√£o qu√¢ntica √© um novo tipo de computa√ß√£o que utiliza fen√¥menos da mec√¢nica qu√¢ntica, como superposi√ß√£o e entrela√ßamento, para resolver problemas complexos que est√£o al√©m das capacidades dos computadores cl√°ssicos.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='prompt')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='resposta')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Quem foi Nicola Tesla?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Nikola Tesla foi um inventor, engenheiro el√©trico, engenheiro mec√¢nico e futurista s√©rvio-americano, mais conhecido por suas contribui√ß√µes para o projeto do sistema moderno de corrente alternada (CA).')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Quem foi Nicola Tesla?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Nikola Tesla foi um inventor e engenheiro s√©rvio-americano conhecido por suas contribui√ß√µes para o sistema de corrente alternada (CA).')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Cite algumas inven√ß√µes dele')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Tesla √© conhecido por suas contribui√ß√µes no projeto do sistema de corrente alternada (CA), motor de indu√ß√£o CA, bobina de Tesla e r√°dio controlado remotamente.')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_2.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7YjscwwZzw7",
        "outputId": "e390706b-5376-464b-8f69-301b7b132a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='O que √© computa√ß√£o qu√¢ntica?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Ah, computa√ß√£o qu√¢ntica, a solu√ß√£o para todos os problemas que voc√™ nunca teve e que provavelmente nunca entender√°. √â basicamente usar as estranhezas do mundo subat√¥mico para fazer c√°lculos que computadores normais levariam uma eternidade (ou duas) para resolver. Mas n√£o se preocupe, voc√™ provavelmente n√£o vai precisar dela para abrir seu e-mail.\\n')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}